---
layout: default_sparse
title: Workshops
permalink: /programme/workshops/
index: 15
---


<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Multisensory Intelligence for Human Perception</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://weihaox.github.io/bmvc2025mpi" target="_blank">https://weihaox.github.io/bmvc2025mpi</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Weihao Xia (Postdoctoral Researcher, University of Cambridge); Jingyuan Sun (Assistant Professor, The University of Manchester); Chenghua Lin (Professor, The University of Manchester); Cengiz Oztireli (Professor, University of Cambridge)</p>
        <p class=" mb-1"><b>Contact: </b>wx258@cam.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>The goal of this workshop is to catalyse a paradigm shift in the AI community’s approach to perception—from a narrowly multimodal perspective to a truly multisensory one. We aim to highlight recent advancements in specialized domains, including computational olfaction, haptic learning, gustatory modelling, and neuro-symbolic integration, while bringing together researchers from diverse fields. In doing so, we hope to encourage cross-pollination of ideas and support the development of AI systems that more accurately reflect the richness and complexity of human perception.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">DIFA: Deep Learning-based Information Fusion and Its Applications</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://difa2025-bmvc.github.io/" target="_blank">https://difa2025-bmvc.github.io/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Xingchen Zhang (Senior Lecturer, University of Exeter); Zhixiang Chen (Lecturer, The University of Sheffield); Shuyan Li (Lecturer, Queen's University Belfast)</p>
        <p class=" mb-1"><b>Contact: </b>x.zhang12@exeter.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>Information fusion has become a key enabler for perception, decision-making, and control across a wide range of domains. By integrating data from multiple sensors, modalities, or sources, it produces more robust and accurate representations of the world. In recent years, the field has significantly expanded in both scope and impact, largely driven by the adoption of deep learning techniques. Advances in multimodal and multi-source fusion have led to notable improvements in diverse applications, including robotics, autonomous driving, medical imaging, remote sensing, surveillance, and infrastructure inspection. Deep learning models—such as CNNs, GANs, autoencoders, transformers, and diffusion models—have further accelerated progress in both fusion methodologies and their downstream applications. This workshop aims to bring together researchers from across the information fusion community to present the latest developments in algorithms, datasets, evaluation strategies, and application-driven solutions. It also seeks to foster cross-disciplinary collaboration by welcoming participants from fields such as computer vision, natural language processing, robotics, healthcare, and remote sensing. By reviewing current trends and exploring future directions, the workshop intends to drive innovation and strengthen community ties in the evolving landscape of information fusion.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Workshop on Machine Vision for Earth Observation and Environment Monitoring</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://mveo.github.io/index.html" target="_blank">https://mveo.github.io/index.html</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Keiller Nogueira (Lecturer, University of Liverpool); Vahid Akbari (Lecturer, University of Stirling); Jan Boehm (Professor, University College London); Fabiana Di Ciaccio (Assistant Professor, University of Florence); Ribana Roscher (Professor, Research Center Jülich and University of Bonn); Ronny Hänsch (German Aerospace Center (DLR)); Chunbo Luo (Associate Professor, University of Exeter); Diego Marcos (Junior Professor, Inria, Université de Montpellier); Paolo Russo (Assistant Professor, Sapienza University of Rome)</p>
        <p class=" mb-1"><b>Contact: </b>keiller.nogueira@liverpool.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>This workshop focuses on advancing Earth Observation, a multidisciplinary research field combining computer vision, machine learning, and signal/image processing to address pressing global challenges (such as climate change, pollution, biodiversity loss, and so on) which span a wide range of applications (including online mapping services, large-scale surveillance, urban modelling, navigation systems, natural hazard forecasting and response, virtual habitat modelling, etc). Specifically, the primary goal of this workshop is to foster collaboration and idea exchange between the Computer Vision, Remote Sensing, and Environmental Monitoring communities, both nationally and internationally. By bringing together researchers and experts from these fields, we aim to promote interdisciplinary research, encourage innovative computer vision approaches for automated interpretation of Earth observation and Environmental data, and enhance knowledge within the Computer Vision community for this rapidly evolving and highly impactful area of research. Overall, the potential outcomes of this research are far-reaching, affecting human society, economy, industry, and the environment.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Media authenticity in the age of artificial intelligence</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://dbhowmik.github.io/MediaTrust/workshops/" target="_blank">https://dbhowmik.github.io/MediaTrust/workshops/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Deepayan Bhowmik (Senior Lecturer, Newcastle University); Frederik Temmermans (imec, Vrije Universiteit Brussel); Sabrina Caldwell (Senior Lecturer, Australian National University)</p>
        <p class=" mb-1"><b>Contact: </b>deepayan.bhowmik@ncl.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>Recent advances in artificial intelligence, especially Generative AI, for media creation and manipulation enable users to produce near-realistic media content that is almost indistinguishable from authentic content to the human eye. These developments open a multitude of opportunities, from creative content production, the art industry, and digital restoration to image and video coding. However, they also risk infringing copyrights and spreading manipulated media, such as deepfakes, which often lead to social unrest, the spread of rumours for political gain, or the encouragement of hate crimes. The workshop aims to solicit papers and talks addressing the current advances in trustworthy media generation, distribution and consumption.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">2nd Workshop on Synthetic Realities and Biometric Security: Advances in Forensic Analysis and Threat Mitigation (SRBS 2025)</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://sites.google.com/view/srbs-bmvc2025/home" target="_blank">https://sites.google.com/view/srbs-bmvc2025/home</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Fadi Boutros (Senior Research Fellow, Fraunhofer Institute for Computer Graphics Research IGD); Naser Damer (Senior Research Fellow, Fraunhofer Institute for Computer Graphics Research IGD and Professor, Technical University Darmstadt); Marija Ivanovska (Assistant, University of Ljubljana); Vishal Patel (Associate Professor, Johns Hopkins University); Ajita Rattani (Assistant Professor, University of North Texas); Anderson Rocha (Full Professor, University of Campinas); Vitomir Štruc (Full Professor, University of Ljubljana)</p>
        <p class=" mb-1"><b>Contact: </b>marija.ivanovska@fe.uni-lj.si</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>Recent advancements in deep learning, including Generative Adversarial Networks (GANs) and Diffusion models, have fueled the generation and detection of highly realistic synthetic images and videos. While such content has applications in entertainment, it also raises serious concerns in security and media, where synthetic data is used to impersonate individuals or spread misinformation. In biometric authentication, manipulated visuals can enable unauthorized access, making robust detection methods essential for preventing breaches and ensuring the integrity of secure systems and public information. The workshop covers a broad range of topics including generative models, image and video synthesis, detection of manipulated content, biometric and physical attacks, forensic analysis, ethical implications, and the role of foundation and multimodal models in generation and detection tasks.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Machine Vision for Climate change</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://mvcc-bmvc.github.io/" target="_blank">https://mvcc-bmvc.github.io/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Lakshmi Babu Saheer (Director of Computing Informatics and Applications Research group, Assistant Professor in AI, Anglia Ruskin University); Mahdi Maktabdar Oghaz (Assistant Professor in AI, Anglia Ruskin University); Jennifer Schooling (Professor in Digital Innovation and Smart Places, Anglia Ruskin University); Manu Sasidharan (Assistant Professor in Infrastructure Asset Management, University College London); Avar Almukhtar (Senior Lecturer in Construction Informatics, School of the Built Environment, Oxford Brookes University); Raul Aquinos Santos (Professor and Chair for TG-AI for Flood Monitoring and Detection and International Telecommunication Union (ITU), Universidad de Colima)</p>
        <p class=" mb-1"><b>Contact: </b>lakshmi.babu-saheer@aru.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>The Machine Vision for Climate Change (MVCC) workshop at BMVC 2025 aims to bring together researchers and practitioners at the intersection of computer vision and environmental sustainability. The workshop will explore how state-of-the-art machine vision techniques, spanning deep learning models, satellite imagery, UAVs, video, and remote sensing can be applied to address critical climate change challenges. We invite contributions focused on sustainable infrastructure, renewable energy, biodiversity, forestry, agriculture, disaster response, air quality, and climate-related public health. Emphasis will also be placed on ethical and responsible AI, including fairness, energy efficiency, and interpretability of vision models in climate applications. MVCC seeks to foster interdisciplinary collaboration and highlight the transformative potential of visual intelligence in building a sustainable and resilient future.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Privacy, Fairness, Accountability and Transparency in Computer Vision</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://sites.google.com/view/pfatcvbmvc25/home" target="_blank">https://sites.google.com/view/pfatcvbmvc25/home</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Fani Deligianni (University of Glasgow); Idris Zakariyya (University of Glasgow); Ng Pai Chet (Singapore Institute of Technology); Jefersson A. dos Santos (The University of Sheffield); Jindong Gu (University of Oxford and DeepMind)</p>
        <p class=" mb-1"><b>Contact: </b>fani.deligianni@glasgow.ac.uk</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>The advances in computer vision research have transformed the way people work and think. Deep learning techniques has outperformed classical machine learning and exceeded human performance, demonstrating the potential to translate computer vision in critical real applications. Nevertheless, applying these techniques broadly in privacy sensitive domains is met with significant hurdles, including ethical considerations, safety, and privacy issues, all of which must be thoroughly considered and resolved prior to widespread adoption. Furthermore, the ethical consideration of employing these technologies to continuous monitoring has been underestimated, since signatures of biometrics can be revealed even when subjects are not directly identifiable. This workshop invites outstanding works on this technically challenging domain to reveal threats and ethical issues and propose solutions. Similarly to last year success (PFATCV@BMVC24), we aim to feature cutting-edge research from both academic institutions and industry partners, fostering valuable discussions on privacy-preserving computer vision techniques.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Smart Cameras for Smarter Autonomous Vehicles and Robots</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://supercamerai.github.io/" target="_blank">https://supercamerai.github.io/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Marcos V. Conde (University of Würzburg and CIDAUT AI); Alvaro Garcia (CIDAUT AI); Daniel Feijoo (CIDAUT AI); Juan Carlos Benito (CIDAUT AI); Lin Gu (University of Tokyo); Arturo Deza (Artificio); Larissa Triess (Mercedes-Benz R&D)</p>
        <p class=" mb-1"><b>Contact: </b>marcos.conde@uni-wuerzburg.de</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>Many advances in the development of autonomous robots and self-driving cars are limited by the embedded sensors. Arguably, the most important sensors in autonomous vehicles and robots are the cameras. The complete navigation and driving pipeline relies on high-quality visual input data. Vision-based algorithms for object recognition and scene understanding are key to ensure proper navigation and interaction in the real-world, however, what happens if the camera gets damaged? What if the visual information is noisy? The safety and proper behavior of many autonomous systems depends on the quality and reliability of the cameras. For this reason, we introduce the 1st workshop "Smart Cameras for Smarter Autonomous Vehicles and Robots" to unify low-level vision, computational photography and robotics.</p>
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">From Scene Understanding to Human Modeling</h4>
        <p class=" mb-1"><b>Website: </b><a href="https://sites.google.com/view/su2hm/home" target="_blank">https://sites.google.com/view/su2hm/home</a></p>
        <p class=" mb-1 text-justify"><b>Organisers: </b>Yousef Yeganeh (Senior Research Associate (PhD Candidate), Technical University of Munich (TUM)); Azade Farshad (Postdoctoral Research Associate, Technical University of Munich (TUM)); Marilyn Keller (Senior Research Associate (PhD Candidate), Max Planck Institute); Nassir Navab (Full Professor, Technical University of Munich (TUM)); Ehsan Adeli (Assistant Professor, Stanford University)</p>
        <p class=" mb-1"><b>Contact: </b>y.yeganeh@tum.de</p>
        <p class=" mb-1"><b>Venue: </b>Cutlers' Hall</p>
        <p class="pb-1 text-justify"><b>Summary: </b>This workshop explores advancements in human modeling and contextual scene analysis within deep learning, crucial for interpreting complex visual environments across various applications like robotics and medical imaging. It emphasizes the accurate modeling of humans and the intricate relationships between all entities in a scene. The workshop will delve into sophisticated human representations (motion, physical plausibility, inferred states) for improved action recognition and behavior prediction, alongside techniques for understanding overall scene context (scene graph prediction, temporal dynamics). A key focus is the interplay between these areas: how detailed human models enhance scene understanding, and how broader scene context refines human modeling. It also highlights emerging datasets and generalized foundation models for jointly reasoning about human behavior and the environment.</p>
    </div>
</div>

{% comment %} 

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Workshop on Machine Vision for Earth Observation and Environment Monitoring</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://mveo.github.io/" target="_blank">https://mveo.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Keiller Nogueira, Lecturer, University of Liverpool; Jan Boehm, University College London; Fabiana Di Ciaccio, Assistant Professor, University of Florence; Ahmed Emam, PhD researcher, University of Bonn; Ronny Hänsch, German Aerospace Center (DLR); Chunbo Luo, University of Exeter; Diego Marcos, Junior Professor, Inria, Universite de Montpellier; Paolo Russo, Assistant Professor, Sapienza University of Rome.</p>
        <p class=" mb-1"><b>Contact:</b> Keiller.Nogueira@liverpool.ac.uk</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The primary goal of this workshop is to foster collaboration and idea exchange between the Computer Vision, Remote Sensing, and Environmental Monitoring communities, both nationally and internationally. We aim to bring together researchers and experts from these  fields to promote interdisciplinary research, encourage innovative computer vision approaches for automated interpretation of Earth observation and Environmental data, and enhance knowledge within the Computer Vision community for this rapidly evolving and highly impactful area of research. The potential outcomes of this research are far-reaching, affecting human society, economy, industry, and the environment.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">The 2nd Workshop in Video Understanding and its Applications</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://vua-bmvc.github.io/2024/" target="_blank">https://vua-bmvc.github.io/2024/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Dr Faegheh Sardari, postdoctoral research fellow in Audio-Visual AI at the CVSSP, University of Surrey; Dr Armin Mustafa, lecturer in computer vision at the CVSSP, University of Surrey; Mr Asmar Nadeem, PhD student on multi-modal video understanding at the CVSSP, University of Surrey; Mr Davide Berghi, research engineer in audio-visual AI at the CVSSP, University of Surrey; Mr Robert Dawes, lead research engineer at the BBC; Prof. Adrian Hilton, full professor in computer vision and signal processing at the CVSSP, University of Surrey.</p>
        <p class=" mb-1"><b>Contact:</b> f.sardari@surrey.ac.uk</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The proposed workshop brings together people working in the video understanding area in the Computer Vision and AI community, with the aim of discovering the general challenges and developing solutions in this area. Automatic analysis of the video plays an important role in many applications, such as video summarization, video highlights, and human action assessment. In our closing panel session, we will discuss the broader impact of video understanding in various real-world applications, which will enable the identification of future research challenges in the field.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Robust Recognition in the Open World</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://rrow2024.github.io" target="_blank">https://rrow2024.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Hermann Blum, ETH Zürich; Hanno Gottschalk, TU Berlin; Kira Maag, TU Berlin; Matthias Rottmann, University of Wuppertal; Siniša Šegvić, University of Zagreb.</p>
        <p class=" mb-1"><b>Contact:</b> rottmann@uni-wuppertal.de</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> This workshop addresses the challenges deep neural networks face with unexpected scenes and environments that differ from training data. We focus on methods and datasets to improve AI robustness and adaptability for critical applications like automated driving, robotics, and medical imaging.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">1st Workshop on Advancing Non-invasive Human Motion Characterization in the Clinical Domain: Methods and Applications</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://anima2024.sites.uu.nl/" target="_blank">https://anima2024.sites.uu.nl/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Lucia Migliorelli, Postdoc, Department of Information Engineering, Marche Polytechnic University; Matteo Moro, Assistant Professor, Department of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS),  University of Genova & Machine Learning Genoa (MaLGa) Center; Ronald Poppe, Associate Professor, Department of Information and Computing Sciences, Utrecht University.</p>
        <p class=" mb-1"><b>Contact:</b> matteo.moro@unige.it</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Our workshop aims to contribute to the broader computer vision community by focusing on those challenges that are inherent, but not unique, to the medical domain. We believe that tackling these topics in behavioral motion analysis within the medical domain will not only advance healthcare technology but also push the boundaries of computer vision research. The workshop recruits high-quality and original research works focused on understanding human behaviour including, but not limited to:</p>
        <ul>
            <li>Motion quantification: measurement of human pose and motion in 2D or 3D.</li>
            <li>Motion classification: detection of specific human motions, training classifiers with limited data.</li>
            <li>Clinical datasets: dealing with data scarcity, privacy, federated learning, synthetic data, and benchmarking.</li>
            <li>Motion recording: use, calibration and combination of various sensors.</li>
            <li>Applications: in the domain of infant analysis, diagnostics and rehabilitation.</li>
            <li>Real-time analysis: algorithms to perform human motion analysis in real-time, enabling applications such as continuous monitoring in clinical settings.</li>
            <li class='text-justify'>Ethical considerations: studies that address ethical implications of using computer vision in healthcare, including issues related to privacy, consent and bias in algorithmic decision-making.</li>
        </ul>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Media Authenticity in the Age of Artificial Intelligence</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://dbhowmik.github.io/MediaTrust/workshops/" target="_blank">https://dbhowmik.github.io/MediaTrust/workshops/</a></p>
        <p class=" mb-1"><b>Organisers:</b> Deepayan Bhowmik, Newcastle University, UK; Frederik Temmermans, Vrije Universiteit Brussel, Belgium; Sabrina Caldwell, Australian National University, Australia.</p>
        <p class=" mb-1"><b>Contact:</b> deepayan.bhowmik@newcastle.ac.uk</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Recent advances in artificial intelligence, especially Generative AI, for media creation and manipulation enable users to produce near-realistic media content that is almost indistinguishable from authentic content to the human eye. These developments open a multitude of opportunities, from creative content production, the art industry, and digital restoration to image and video coding. However, they also risk infringing copyrights and spreading manipulated media, such as deepfakes, which often lead to social unrest, the spread of rumours for political gain, or the encouragement of hate crimes. The proposed workshop aims to solicit papers and talks addressing the current advances in trustworthy media generation, distribution and consumption. This includes but is not limited to, the use of machine learning / artificial intelligence in</p>
        <ul>
            <li>Generative AI and media trust</li>
            <li>Media privacy and security</li>
            <li>Media manipulation (including deepfake) detection</li>
            <li>AI-generated media content identification</li>
            <li>Media integrity, authenticity and provenance</li>
            <li>Initiatives to standardisation and policy</li>
            <li>Media authenticity use cases</li>
        </ul>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2161.544657596555!2d-2.2023420229653876!3d57.19611637990996!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x4884113d4bea3415%3A0x5dac74377f681031!2sNational%20Subsea%20Centre!5e0!3m2!1sen!2sus!4v1698418405363!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">DIFA: Deep Learning-based Image Fusion and Its Applications</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://difa2024.github.io/" target="_blank">https://difa2024.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Xingchen Zhang, Senior Lecturer, University of Exeter; Zhixiang Chen, Lecturer, University of Sheffield; Shuyan Li, Incomining lecturer at Queen's University Belfast; Yiannis Demiris, Professor, Imperial College London.</p>
        <p class=" mb-1"><b>Contact:</b> x.zhang12@exeter.ac.uk</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Image fusion, with its expansive applications from surveillance and autonomous driving to medical diagnostics, has become a hot topic in recent years. Its relevance to the computer vision community is clear: as computer vision techniques evolve, the integration of varied image sources is crucial for pushing research boundaries. Beyond the computer vision community, the workshop holds wider appeal. Fields such as robotics, biometric recognition, medical image processing, and computational photography benefit from image fusion advancements. As the lines between traditional computer vision and these research fields blur, the discussions and insights from this workshop are positioned to inspire a broad spectrum of researchers and practitioners, emphasizing the value of interdisciplinary dialogue and collaboration.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Synthetic Realities and Biometric Security: Advances in Forensic Analysis and Threat Mitigation (SRBS)</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://sites.google.com/view/srbs-bmvc2024" target="_blank">https://sites.google.com/view/srbs-bmvc2024</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Naser Damer, Senior Research Fellow, Fraunhofer Institute for Computer Graphics Research IGD, Germany; Marija Ivanovska, Assistant, University of Ljubljana; Vishal Patel, Associate Professor, Johns Hopkins University; Ajita Rattani, University of North Texas; Anderson Rocha, Full Professor, University of Campinas; Vitomir Štruc, Full Professor, University of Ljubljana, Slovenia.</p>
        <p class=" mb-1"><b>Contact:</b> marija.ivanovska@fe.uni-lj.si</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Recent advancements in deep learning algorithms, such as Generative Adversarial Networks (GANs) and Diffusion models, have led to a surge in the creation of highly realistic images and videos, which are often indistinguishable from genuine content to the human eye. While these developments have benefited the entertainment industry, they are often used to spread misinformation and manipulate public opinion. Moreover, in the security domain, synthetic and manipulated images and videos are frequently utilized to impersonate individuals, enabling unauthorized parties to bypass systems for biometric authentication gaining illegal access to sensitive information. Accurate detection of fake data is crucial for preventing security breaches and safeguarding the integrity of security measures and public information.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Privacy, Fairness, Accountability and Transparency in Computer Vision</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://sites.google.com/view/pfatcvbmvc24/home" target="_blank">https://sites.google.com/view/pfatcvbmvc24/home</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Dr. Fani Deligianni, University of Glasgow; Dr. Idris Zakariyya, University of Glasgow; Dr. Ng Pai Chet, Singapore Institute of Technology; Prof. Mubarak Shah, Center for Research in Computer Vision, University of Central Florida.</p>
        <p class=" mb-1"><b>Contact:</b> fani.deligianni@glasgow.ac.uk</p>
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The advances in computer vision research have transformed the way people work and think. Deep learning techniques has outperformed classical machine learning and exceeded human performance, demonstrating the potential to translate computer vision in critical real applications. Nevertheless, applying these techniques broadly in privacy sensitive domains is met with significant hurdles, including ethical considerations, safety, and privacy issues, all of which must be thoroughly considered and resolved prior to widespread adoption. Furthermore, the ethical consideration of employing these technologies to continuous monitoring has been underestimated, since signatures of biometrics can be revealed even when subjects are not directly identifiable. This workshop invites outstanding works on this technically challenging domain to reveal threats and ethical issues and propose solutions.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

{% endcomment %} 