<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Chun-Hsiao Yeh (Meta), Ta-Ying Cheng (University of Oxford), He-Yen Hsieh (Harvard University), David Chuan-En Lin (Carnegie Mellon University), Yi Ma (University of Hong Kong), Andrew Markham (University of Oxford), Niki Trigoni (University of Oxford), H. T. Kung (Harvard University), Yubei Chen (University of California)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2025.bmva.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_28/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_28/28_supplementary.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>In this paper, we identify two major gaps in personalizing text-to-image diffusion models, i.e., placing personalized concepts into generated image: 1) Creating a high-quality multi-concept personalized dataset with detailed and aligned text descriptions is challenging. 2) There lacks  comprehensive metrics to evaluate multiple personalized concepts in an image. To overcome these challenges, we propose Gen4Gen, a novel generative data pipeline for creating a benchmark dataset (MyCanvas) that combines personalized concepts into complex compositions aligning with detailed text descriptions, aiming to benchmark and improve multi-concept personalization. In addition, we introduce comprehensive metrics (CP-CLIP / TI-CLIP) for evaluating the performance of multi-concept personalization models more effectively. Finally, we provide a simple yet effective baseline built on top of several personalization methods with empirical prompting strategies for future researchers to evaluate on MyCanvas benchmark. By improving data quality, we can significantly increase the multi-concept image generation quality without changing the model architecture or training algorithms, and we show our work can be simply plug in to personalization approaches. We suggest that leveraging strong foundation models for dataset generation could benefit various computer vision tasks. Code and benchmark dataset are available at https://danielchyeh.github.io/Gen4Gen/.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Yeh_2025_BMVC,
author    = {Chun-Hsiao Yeh and Ta-Ying Cheng and He-Yen Hsieh and David Chuan-En Lin and Yi Ma and Andrew Markham and Niki Trigoni and H. T. Kung and Yubei Chen},
title     = {Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition},
booktitle = {36th British Machine Vision Conference 2025, {BMVC} 2025, Sheffield, UK, November 24-27, 2025},
publisher = {BMVA},
year      = {2025},
url       = {https://bmva-archive.org.uk/bmvc/2025/papers/Paper_28/paper.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2025 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>