<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>PME3D: An Adaptive and Efficient Multi-modal Feature Extraction Plug-in for 3D Object Detection</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>PME3D: An Adaptive and Efficient Multi-modal Feature Extraction Plug-in for 3D Object Detection</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Tianyi Yu (Beijing University of Aeronautics and Astronautics), Lei Yu (Beihang University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2025.bmva.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_310/paper.pdf" role="button">PDF</a><br></div><h2 id="abstract">Abstract</h2>3D object detection is fundamental to autonomous driving systems, where efficiently fusing multi-modal sensor data remains a critical challenge. Although current approaches predominantly focus on improving detection accuracy through Bird's Eye View representations, they often overlook computational efficiency, a crucial factor for real-world deployment on resource-constrained automotive platforms. To bridge this gap, we propose a lightweight plug-in module that enhances feature fusion efficiency through two key mechanisms: 1) dimensionality inversion of feature extraction outputs, and 2) dynamic selection of camera features for optimal fusion with point cloud data. Our experiments on nuScenes demonstrate that this approach maintains competitive detection performance while significantly reducing computational overhead, offering a practical solution for real-time autonomous driving applications.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Yu_2025_BMVC,
author    = {Tianyi Yu and Lei Yu},
title     = {PME3D: An Adaptive and Efficient Multi-modal Feature Extraction Plug-in for 3D Object Detection},
booktitle = {36th British Machine Vision Conference 2025, {BMVC} 2025, Sheffield, UK, November 24-27, 2025},
publisher = {BMVA},
year      = {2025},
url       = {https://bmva-archive.org.uk/bmvc/2025/papers/Paper_310/paper.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2025 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>