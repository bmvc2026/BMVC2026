<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Dynamic Convolution and Graph-Coupled Attention for Cross-Subject EEG-Vision Decoding</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Dynamic Convolution and Graph-Coupled Attention for Cross-Subject EEG-Vision Decoding</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Tianyu Zhang (Durham University), FAN WAN (Durham University), Kaili Sun (Durham University), Xingyu Miao (Durham University), Yueming Sun (University of Durham), Minye Shao (Durham University), Yang Long (Durham University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2025.bmva.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_509/paper.pdf" role="button">PDF</a><br></div><h2 id="abstract">Abstract</h2>Electroencephalography (EEG) offers a non-invasive route to visual object decoding, but practical deployment is hampered by the signals’ non-stationarity, low signal-to-noise ratio and pronounced inter-subject variability. Existing models employ fixed convolutional filters and therefore generalize poorly across subjects. We introduce \textit{ECHO-Net}—an adaptive, hierarchically organised network that assembles dynamic convolutional kernels, conditioning them on each incoming EEG trial to capture transient neural dynamics. A cross-modal contrastive objective aligns the resulting representations with CLIP image embeddings, while a channel–filter attention mechanism emphasises task-relevant electrodes and time–frequency bands. To regularise spatial structure, an embedded EEG-GAT module propagates information over a fully connected electrode graph, producing more consistent cross-subject features. Evaluated on the 200-way THINGS-EEG benchmark, our method attains 18.5\% top-1 and 44.1\% top-5 cross-subject accuracy—surpassing the strongest prior approach by 2.9\% top-1.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Zhang_2025_BMVC,
author    = {Tianyu Zhang and FAN WAN and Kaili Sun and Xingyu Miao and Yueming Sun and Minye Shao and Yang Long},
title     = {Dynamic Convolution and Graph-Coupled Attention for Cross-Subject EEG-Vision Decoding},
booktitle = {36th British Machine Vision Conference 2025, {BMVC} 2025, Sheffield, UK, November 24-27, 2025},
publisher = {BMVA},
year      = {2025},
url       = {https://bmva-archive.org.uk/bmvc/2025/papers/Paper_509/paper.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2025 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>