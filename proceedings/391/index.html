<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Depth Inconsistency-based spatial-channel attention gate for Mirror Segmentation</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Depth Inconsistency-based spatial-channel attention gate for Mirror Segmentation</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Ritsuki Kurohiji (Wakayama University), Hirotaka Hachiya (Wakayama University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2025.bmva.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_391/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_391/391_supplementary.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>We propose a novel depth-aware mirror and specular object segmentation framework that leverages the contextual inconsistency between two types of depth information: time-of-flight (ToF) measurements and depth predicted by a deep neural network. ToF depth values are often significantly overestimated near mirrors due to indirect light paths, while predicted depth maps tend to be overly smoothed in those regions. We observe that this contextual discrepancy serves as a strong cue for identifying mirror regions. However, direct comparison between these depths in either the image or feature space results in high false positive rates, primarily due to their inherently different value ranges and responses to scene content. To address this issue, we introduce a depth inconsistency-based spatial-channel Attention Gate (discAG), which adaptively highlights informative regions in ToF feature maps based on spatial- and channel-wise extracted depth context inconsistencies. By integrating discAG into a segmentation architecture, our method achieves superior performance compared to state-of-the-art approaches. Experimental results on the RGB-D Mirror Segmentation dataset and our newly constructed Specular Object dataset demonstrate the effectiveness of our approach, particularly in challenging scenarios involving small or frameless mirrors.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Kurohiji_2025_BMVC,
author    = {Ritsuki Kurohiji and Hirotaka Hachiya},
title     = {Depth Inconsistency-based spatial-channel attention gate for Mirror Segmentation},
booktitle = {36th British Machine Vision Conference 2025, {BMVC} 2025, Sheffield, UK, November 24-27, 2025},
publisher = {BMVA},
year      = {2025},
url       = {https://bmva-archive.org.uk/bmvc/2025/papers/Paper_391/paper.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2025 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>