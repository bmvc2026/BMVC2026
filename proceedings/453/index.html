<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>HalfMix Augmentation and Regularized Dual-Path Learning for Cross-Domain Gaze Estimation</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>HalfMix Augmentation and Regularized Dual-Path Learning for Cross-Domain Gaze Estimation</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Jiuk Hong (Kyungpook National University), Heechul Jung (Kyungpook National University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2025.bmva.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2025/papers/Paper_453/paper.pdf" role="button">PDF</a><br></div><h2 id="abstract">Abstract</h2>Cross-domain gaze estimation presents a persistent challenge in computer vision, as models often experience significant performance degradation when applied to unseen target domains with different characteristics (e.g., subjects, illumination, camera setups). To address this, we first introduce HalfMix augmentation, a novel data augmentation technique specifically designed for gaze estimation. HalfMix mitigates common issues in conventional mix-based augmentations like MixUp and CutMix by preserving crucial eye regions without overlap or occlusion. Secondly, we propose a regularized dual-path learning strategy to effectively capitalize on the rich, dual-gaze information inherent in HalfMix-generated samples. This strategy employs a dual-path architecture where a shared encoder feeds into two distinct prediction pathways. To foster diverse and robust feature learning, we incorporate two key regularization components: diversity promoting regularization (DPR) and dual-gaze feature alignment (DGFA). Extensive experiments on several benchmark datasets demonstrate that our integrated approach significantly improves cross-domain gaze estimation performance, outperforming existing methods by learning more robust and generalizable gaze representations that are less sensitive to domain shifts. Code is available at https://github.com/CreamNuts/HalfMix-Dual-Path-Learning.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Hong_2025_BMVC,
author    = {Jiuk Hong and Heechul Jung},
title     = {HalfMix Augmentation and Regularized Dual-Path Learning for Cross-Domain Gaze Estimation},
booktitle = {36th British Machine Vision Conference 2025, {BMVC} 2025, Sheffield, UK, November 24-27, 2025},
publisher = {BMVA},
year      = {2025},
url       = {https://bmva-archive.org.uk/bmvc/2025/papers/Paper_453/paper.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2025 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>